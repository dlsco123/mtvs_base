{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "#from sklearn.metrics import r2_score\n",
    "#from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "##########데이터 로드\n",
    "\n",
    "x_data = np.array([\n",
    "    [2, 1],\n",
    "    [3, 2],\n",
    "    [3, 4],\n",
    "    [5, 5],\n",
    "    [7, 5],\n",
    "    [2, 5],\n",
    "    [8, 9],\n",
    "    [9, 10],\n",
    "    [6, 12],\n",
    "    [9, 2],\n",
    "    [6, 10],\n",
    "    [2, 4]\n",
    "])\n",
    "y_data = np.array([3, 5, 7, 10 ,12, 7, 13, 13, 12, 13, 12, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['alpha', 'copy_X', 'fit_intercept', 'max_iter', 'positive', 'precompute', 'random_state', 'selection', 'tol', 'warm_start'])\n",
      "{'alpha': 0.5}\n",
      "-2.893834505364599\n",
      "           params  mean_test_score\n",
      "0  {'alpha': 0.5}        -2.893835\n",
      "1    {'alpha': 1}        -3.618589\n",
      "2  {'alpha': 1.5}        -4.449471\n",
      "8.34598670632434\n"
     ]
    }
   ],
   "source": [
    "##########데이터 분석\n",
    "\n",
    "##########데이터 전처리\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=777)\n",
    "\n",
    "##########모델 생성\n",
    "\n",
    "model = Lasso()\n",
    "\n",
    "##########모델 학습\n",
    "\n",
    "##########모델 검증\n",
    "\n",
    "print(model.get_params().keys()) #\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.5, 1, 1.5]\n",
    "}\n",
    "grid_search = GridSearchCV(model, param_grid=param_grid) \n",
    "#grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, scoring='r2') \n",
    "#grid_search = GridSearchCV(model, param_grid=param_grid, cv=KFold(n_splits=5), scoring='r2') \n",
    "#grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, scoring=make_scorer(r2_score))\n",
    "#grid_search = GridSearchCV(model, param_grid=param_grid, cv=KFold(n_splits=5), scoring=make_scorer(r2_score))\n",
    "\n",
    "grid_search.fit(x_data, y_data)\n",
    "\n",
    "print(grid_search.best_params_) #{'alpha': 0.5}\n",
    "print(grid_search.best_score_) #-2.8938345053645973\n",
    "df = pd.DataFrame(grid_search.cv_results_)\n",
    "df = df.sort_values(by='mean_test_score', ascending=False)\n",
    "print(df[['params', 'mean_test_score']])   \n",
    "'''\n",
    "           params  mean_test_score\n",
    "0  {'alpha': 0.5}        -2.893835\n",
    "1    {'alpha': 1}        -3.618589\n",
    "2  {'alpha': 1.5}        -4.449471\n",
    "'''\n",
    "\n",
    "##########모델 예측\n",
    "\n",
    "x_test = np.array([\n",
    "    [4, 6]\n",
    "])\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_predict = best_model.predict(x_test)\n",
    "\n",
    "print(y_predict[0]) #8.279504382440336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Father\n",
      "0  165.100\n",
      "1  165.100\n",
      "2  167.132\n",
      "3  155.194\n",
      "4  160.020\n",
      "0.24967004992776765\n",
      "0.25199779058466176\n",
      "170.46931035654347\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "##########데이터 로드\n",
    "\n",
    "train_df = pd.read_excel('https://github.com/cranberryai/todak_todak_python/blob/master/machine_learning/regression/%E1%84%8B%E1%85%A1%E1%84%87%E1%85%A5%E1%84%8C%E1%85%B5%E1%84%8B%E1%85%A1%E1%84%83%E1%85%B3%E1%86%AF%E1%84%8F%E1%85%B5.xlsx?raw=true', sheet_name='train')\n",
    "test_df = pd.read_excel('https://github.com/cranberryai/todak_todak_python/blob/master/machine_learning/regression/%E1%84%8B%E1%85%A1%E1%84%87%E1%85%A5%E1%84%8C%E1%85%B5%E1%84%8B%E1%85%A1%E1%84%83%E1%85%B3%E1%86%AF%E1%84%8F%E1%85%B5.xlsx?raw=true', sheet_name='test')\n",
    "\n",
    "##########데이터 분석\n",
    "\n",
    "##########데이터 전처리\n",
    "\n",
    "x_train = train_df.drop(['Son'], axis=1)\n",
    "x_test = test_df.drop(['Son'], axis=1)\n",
    "y_train = train_df['Son']\n",
    "y_test = test_df['Son']\n",
    "\n",
    "print(x_train.head())\n",
    "'''\n",
    "    Father\n",
    "0  160.782\n",
    "1  166.116\n",
    "2  165.608\n",
    "3  169.672\n",
    "4  176.530\n",
    "'''\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "\n",
    "##########모델 생성\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "##########모델 학습\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "##########모델 검증\n",
    "\n",
    "print(model.score(x_train, y_train)) #\n",
    "\n",
    "print(model.score(x_test, y_test)) #0.251997790584662\n",
    "\n",
    "if not os.path.exists('models/son_height_regression_model'):\n",
    "    os.makedirs('models/son_height_regression_model')\n",
    "\n",
    "with open('models/son_height_regression_model/model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "##########모델 예측\n",
    "\n",
    "x_test = np.array([\n",
    "    [164.338]\n",
    "])\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "print(y_predict[0]) #169.66660924268297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Monty P', '10cept', 'Star Wars']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "movieList = ['Monty P','10cept','Star Wars']\n",
    "\n",
    "#picking: serialize\n",
    "outFile = open('mydata.pickle','wb')\n",
    "pickle.dump(movieList, outFile)\n",
    "outFile.close()\n",
    "\n",
    "#unpicking: deserialize\n",
    "inFile = open('mydata.pickle','rb')\n",
    "newList = pickle.load(inFile)\n",
    "inFile.close()\n",
    "\n",
    "print(newList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/exam_score_regression_model/model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodels/exam_score_regression_model/model.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m      5\u001b[0m \u001b[39m#import pickle\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m#f = open('exam_score_regression_model.pkl', 'rb')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m#model = pickle.load(f)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m#f.close()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\py\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/exam_score_regression_model/model.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('models/exam_score_regression_model/model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "#import pickle\n",
    "#f = open('exam_score_regression_model.pkl', 'rb')\n",
    "#model = pickle.load(f)\n",
    "#f.close()\n",
    "\n",
    "\n",
    "print(model.predict([[2,1]])[0]) #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
